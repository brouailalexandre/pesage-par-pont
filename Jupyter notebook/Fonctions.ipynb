{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion mathématique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kN_t(kN=0, t_kg=0, unite_sortie='t'):\n",
    "    '''\n",
    "    Convertisseur kN <-> t, kg\n",
    "        param: kN - kiloNewton\n",
    "               t_kg - tonne ou kilogramme\n",
    "               unite_sortie - Unité attendue en sortie de calcul : kN, t ou kg\n",
    "        return: (float) Résultat du calcul de convertion\n",
    "    '''\n",
    "    \n",
    "    if unite_sortie == 'kN':\n",
    "        return t_kg/0.102\n",
    "    elif unite_sortie == 't':\n",
    "        return kN*0.102\n",
    "    elif unite_sortie == 'kg':\n",
    "        return kN*102\n",
    "    else:\n",
    "        print(\"L'unité n'est pas reconnue.\\nChoix possible : \\n\\t- kN (kiloNewtons)\\n\\t- t (tonnes)\\n\\t- kg (kilogrammes)\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_kmh(ms=0, kmh=0, unite_sortie='kmh'):\n",
    "    '''\n",
    "    Convertisseur m/s <-> km/h\n",
    "        param: ms - Mètre / seconde\n",
    "               kmh - Kilomètre / heure\n",
    "               unite_sortie - Unité attendue en sortie de calcul : ms ou kmh\n",
    "        return: (float) Résultat du calcul de convertion\n",
    "    '''\n",
    "    \n",
    "    if unite_sortie == 'kmh':\n",
    "        return ms*3.6\n",
    "    elif unite_sortie == 'ms':\n",
    "        return kmh/3.6\n",
    "    else:\n",
    "        print(\"L'unité n'est pas reconnue.\\nChoix possible : \\n\\t- kmh (km/h)\\n\\t- ms (m/s)\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_dec(element):\n",
    "        new_list = []\n",
    "        for elt in element:\n",
    "            new_list.append(int(elt, 16))\n",
    "            \n",
    "        return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage Series et conversion DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Découpage des 'Warning Flags' et conversion en int\n",
    "    param: WF_series - Warning Flags Series\n",
    "    return: (DataFrame - int64) 8 colonnes contenant les warning flags par groupe de bits\n",
    "'''\n",
    "def warningFlags_dummies(WF_series):\n",
    "    def normalisation_warningFlags(element):\n",
    "        limit = 8 # Fixed by norm .nswd files\n",
    "        len_elt = len(element)\n",
    "        add_list = []\n",
    "        for i in range(limit):\n",
    "            add_list.append('0')\n",
    "\n",
    "        if len_elt <= limit:\n",
    "            alpha = limit-len_elt\n",
    "            element = add_list[:alpha] + element\n",
    "\n",
    "        return element\n",
    "    \n",
    "    normalisationWarningFlags = WF_series.apply(lambda x: normalisation_warningFlags(hex_to_dec(list(x))))\n",
    "    warnings = pd.DataFrame.from_items(zip(normalisationWarningFlags.index, normalisationWarningFlags.values),\\\n",
    "                                       columns=['W7', 'W6', 'W5', 'W4', 'W3', 'W2', 'W1', 'W0'], orient='index')\n",
    "    \n",
    "    return warnings.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Découpage du 'timestamp' et conversion en int\n",
    "    param: TS_series - Timestamp Series\n",
    "    return: (Dataframe - int64) 7 colonnes contenant respectivement une donnée du timestamp: Year, Month, Day, ...\n",
    "'''\n",
    "def timestamp_dummies(TS_series):\n",
    "    splitTimestamp = TS_series.str.split('-')\n",
    "    time = pd.DataFrame.from_items(zip(splitTimestamp.index, splitTimestamp.values),\\\n",
    "                                   columns=['Year', 'Month', 'Day', 'Hour', 'Minute', 'Seconde', 'Millisecondes'],\\\n",
    "                                   orient='index')\n",
    "    \n",
    "    return time.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Découpage de 'axle groups' et conversion en int\n",
    "    param: AG_series - Axle Groups Series\n",
    "    return: (Dataframe - int64) x colonnes dépendant du nombre d'axes totals de AG_series contenant respectivement un\n",
    "            roupe d'axe chacune\n",
    "'''\n",
    "def axleGroups_dummies(AG_series):\n",
    "    limit = np.max(AG_series.apply(lambda x: len(x)))\n",
    "    \n",
    "    def normalisation_axleGroups(element, limit):\n",
    "        len_elt = len(element)\n",
    "        add_list = []\n",
    "        for i in range(limit):\n",
    "            add_list.append('0')\n",
    "\n",
    "        if len_elt <= limit:\n",
    "            alpha = limit-len_elt\n",
    "            element += add_list[:alpha]\n",
    "\n",
    "        return element\n",
    "    \n",
    "    normalisationAxleGroups = AG_series.apply(lambda x: normalisation_axleGroups(hex_to_dec(list(x)), limit))\n",
    "\n",
    "    # Création colonnes axle groups\n",
    "    columns = []\n",
    "    base_name = 'AG_'\n",
    "    for i in range(1,limit+1):\n",
    "        columns.append(base_name + str(i))\n",
    "    \n",
    "    axle = pd.DataFrame.from_items(zip(normalisationAxleGroups.index, normalisationAxleGroups.values),\\\n",
    "                                       columns=columns, orient='index')\n",
    "    \n",
    "    return axle.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche sur DataFrame ou Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recherche éléments uniques dans pandas Series\n",
    "    param: Series - Pandas Series où rechercher les éléments uniques\n",
    "    return: (DataFrame) Ensemble des éléments uniques du pandas Series\n",
    "'''\n",
    "def unique_element(Series):\n",
    "    element = []\n",
    "    for val in Series:\n",
    "        if val not in element:\n",
    "            element.append(val)\n",
    "            \n",
    "    return pd.DataFrame(element, columns=[Series.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recherche éléments uniques dans pandas dataframe\n",
    "    param: DataFrame - Pandas DataFrame où rechercher les éléments uniques\n",
    "    return: (DataFrame) Ensemble des éléments uniques de la pandas DataFrame\n",
    "'''\n",
    "def unique_element_df(DataFrame):\n",
    "    df = pd.DataFrame()\n",
    "    for col in DataFrame:\n",
    "        df = pd.concat([df, unique_element(DataFrame[col])], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_null(DataFrame):\n",
    "    '''\n",
    "    Comptage des élements NaN par colonne dans DataFrame\n",
    "        param: DataFrame - DataFrame où l'on cherche à compter les NaN \n",
    "        return: (DataFrame) Listant l'ensemble des colonnes en comptant leur nombre de NaN\n",
    "    '''\n",
    "    return pd.DataFrame(data={'Missing':DataFrame.isnull().sum()}).sort_values(['Missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste redondante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Création liste charge sur essieux et distance entre essieux\n",
    "    param: bare_str_var - String contenant le préfix de la variable avant le chiffre incrémenté\n",
    "           var_from - Int de départ de l'incrémentation de la liste\n",
    "           var_to - Int de fin de la liste\n",
    "    return: (list) Liste de l'ensemble des variables incrémentés commençant par 'bare_str_var'\n",
    "'''\n",
    "def list_multiple_var(bare_str_var, var_from=1, var_to=1):\n",
    "    list_return = []\n",
    "    \n",
    "    try:\n",
    "        if var_from > var_to:\n",
    "            raise ValueError\n",
    "        \n",
    "        for i in range(var_from, var_to+1):\n",
    "            list_return.append(bare_str_var+'{}'.format(i))\n",
    "            \n",
    "        return list_return\n",
    "        \n",
    "    except ValueError:\n",
    "        print(\"'var_from' doit être inférieur ou égale à 'var_to'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fichiers système"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_extension(source, extension):\n",
    "    '''\n",
    "        Récupérer chemins des fichiers avec 'extension'\n",
    "        param:\n",
    "            - (source : str) String de chemin parent ou commencer à chercher les fichiers\n",
    "            - (extension : str) String de l'extension à rechercher\n",
    "        return: (list) Tous les chemins des fichiers avec 'extension'\n",
    "    '''\n",
    "    \n",
    "    list_ext = []\n",
    "    for elt in glob.glob(source):\n",
    "        if os.path.isdir(elt):\n",
    "            list_ext.extend(find_all_extension(elt + '\\\\*', extension))\n",
    "        else:\n",
    "            if extension in elt:\n",
    "                list_ext.append(elt)\n",
    "          \n",
    "    return list_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nswd_association(path, dest_file):\n",
    "    '''\n",
    "        Association en un fichier des .nswd d'un dossier\n",
    "        param:\n",
    "            - (path : str) String de chemin où se situe les fichiers .nswd\n",
    "            - (dest_file : str) String du nom de fichier qui contiendra tous l'association des fichiers\n",
    "        return: /\n",
    "    '''    \n",
    "    \n",
    "    dest_nswd = path + '\\\\' + dest_file\n",
    "    extension = '.nswd'\n",
    "\n",
    "    nswd = find_all_extension(path, extension)\n",
    "    with open(dest_nswd, 'w') as file_dest:\n",
    "        for elt in nswd:\n",
    "            with open(elt, 'r') as file_src:\n",
    "                result = file_src.read()\n",
    "                file_dest.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sig_trucks_json(dict_trucks, directory=\"backup/\", filename=\"backup_trucks.json\"):\n",
    "    '''\n",
    "        Conversion et sauvegarde des meilleurs signaux selectionnés pour chacun des camions dans un fichier .json.\n",
    "        __________\n",
    "        param:\n",
    "            - (filename : str) Nom de fichier de destination de la sauvegarde\n",
    "            - (directory : str) Dossier de sauvegarde des fichiers .json\n",
    "            - (dict_trucks : dict) Dictionnaire (key : nom fichier, value: dataframe time, amplitude)\n",
    "    '''\n",
    "    \n",
    "    trucks_save = {}\n",
    "    for name_truck, signaux_truck in dict_trucks.items():\n",
    "        # Creation dict pour sauvegarde\n",
    "        trucks_save[name_truck] = signaux_truck.sort_index().to_json()\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    \n",
    "    with open(directory+filename, 'w') as file:\n",
    "        json.dump(trucks_save, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_sig_trucks_load(directory=\"backup/\", filename=\"backup_trucks.json\"):\n",
    "    '''\n",
    "        Chargement et conversion des meilleurs signaux selectionnés pour chacun des camions dans un dictionnaire (key : nom fichier, value: dataframe time, amplitude).\n",
    "        __________\n",
    "        param:\n",
    "            - (directory : str) Dossier de sauvegarde des fichiers .json\n",
    "            - (filename : str) Nom de fichier de destination de la sauvegarde\n",
    "        __________\n",
    "        return: Dictionnaire chargé du json\n",
    "    '''\n",
    "    \n",
    "    with open(directory+filename, 'r') as file:\n",
    "        trucks_saved = json.load(file)\n",
    "        \n",
    "    trucks = {}\n",
    "    for name_truck, signaux_truck in trucks_saved.items():\n",
    "        trucks[name_truck] = pd.read_json(signaux_truck).sort_index().T.reindex(['time', 'amplitude']).T\n",
    "        \n",
    "    return trucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signaux event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_sig(file, sig_list):\n",
    "    '''\n",
    "        Récupération du ou des signaux des poids lourds voulu\n",
    "        __________\n",
    "        \n",
    "        param:\n",
    "            - (file : str) Chemin du fichier où récupérer les signaux\n",
    "            - (sig_list : list) Liste des signaux à récupérer\n",
    "        __________\n",
    "            \n",
    "        return: (DafaFrame) contenant le temps et une colonne par signal pour le fichier passé\n",
    "    '''\n",
    "    \n",
    "    # Récupération de tous les signaux de 'file'\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(line.split())\n",
    "    \n",
    "    # Index des signaux voulu\n",
    "    numbers = []\n",
    "    for sig in sig_list:\n",
    "        numbers.append(int(sig[-2:]))\n",
    "    \n",
    "    sig_df = pd.DataFrame(data).iloc[:,[0] + numbers]\n",
    "    \n",
    "    # Création nom colonne\n",
    "    sig_df.columns = ['time'] + sig_list\n",
    "    \n",
    "    # Création nom signal\n",
    "    name = file.split('\\\\')[-1].split('.')[0]\n",
    "    \n",
    "    return (name, sig_df.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_signal(signaux_truck):\n",
    "    '''\n",
    "        Calcul rapport Signal à bruit pour connaître le meilleur signal et le récupérer\n",
    "        __________\n",
    "        \n",
    "        param:\n",
    "            - (signaux_truck : DataFrame) Ensemble des signaux récupérer sur tous les capteurs d'un camion\n",
    "        __________\n",
    "        \n",
    "        return: (DataFrame) contenant le meilleur signal avec time et amplitude\n",
    "    '''\n",
    "    \n",
    "    # Calcul rapport signal à bruit (Plus c'est grand, mieux c'est !)\n",
    "    S_N = pd.DataFrame()\n",
    "    for signal in signaux_truck.columns[1:]:\n",
    "        df = pd.DataFrame([[signal, signaux_truck.loc[:,signal].std()/signaux_truck.loc[:int(0.3*len(signaux_truck)),signal].std()]],\\\n",
    "                          columns=[\"Name\", \"S/N\"])\n",
    "        S_N = S_N.append(df)\n",
    "        \n",
    "    # Selection meilleur signal\n",
    "    S_N_sort = S_N.reset_index(drop=True).sort_values(by=\"S/N\", ascending=False)\n",
    "    best_signal = pd.DataFrame([signaux_truck.loc[:,signaux_truck.columns[0]],\\\n",
    "                                signaux_truck.loc[:,S_N_sort.loc[0,\"Name\"]]]).T\n",
    "    best_signal.columns = [\"time\", \"amplitude\"]\n",
    "    \n",
    "    return best_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_all_best_signal(search_path, extension='.txt', backup_path=\"backup/backup_trucks.json\"):\n",
    "    '''\n",
    "        Récupération du meilleur signal pour chacun des camions du 'search_path' donné\n",
    "        __________\n",
    "        \n",
    "        param:\n",
    "            - (search_path : str) Chemin dans lequel rechercher les fichiers avec 'extension'\n",
    "            - (extension : str) Extension à rechercher\n",
    "            - (backup_path : str) Chemin d'enregistrement de la sauvegarde\n",
    "        __________\n",
    "        \n",
    "        return: (Dictionnaire) avec key : nom fichier et value: dataframe time, amplitude\n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(backup_path):\n",
    "        trucks = {}\n",
    "        files = find_all_extension(search_path, extension)\n",
    "        for file in files:\n",
    "            # Récupération des signaux\n",
    "            siwim_sig = list_multiple_var('A0', var_to=9) + list_multiple_var('A', 10, 21)\n",
    "            signaux = recover_sig(file, siwim_sig)\n",
    "            trucks[signaux[0]] = signaux[1]\n",
    "    \n",
    "    \n",
    "        for name_truck, signaux_truck in trucks.items():\n",
    "            # Calcul et selection meilleur signal\n",
    "            best_signal = select_best_signal(signaux_truck)\n",
    "\n",
    "            # Remplacement tout signaux par meilleur signal et remise à 0\n",
    "            trucks[name_truck] = supperposition_signaux(best_signal, 10)\n",
    "            \n",
    "            # Sauvegarde meilleurs signaux\n",
    "            bkp_path = backup_path.split(\"/\")\n",
    "            save_sig_trucks_json(trucks, filename=bkp_path[1], directory=bkp_path[0]+\"/\")\n",
    "            \n",
    "    else:\n",
    "        # Récupération signaux sauvegardés\n",
    "        bkp_path = backup_path.split(\"/\")\n",
    "        trucks = json_sig_trucks_load(directory=bkp_path[0]+\"/\", filename=bkp_path[1])\n",
    "        \n",
    "    return trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supperposition_signaux(signaux, delta):\n",
    "    '''\n",
    "        Supperposition des signaux en les remontants à 0\n",
    "        __________\n",
    "        \n",
    "        param:\n",
    "            - (signaux : DataFrame) Dataframe des signaux intéressants du poids lourds\n",
    "            - (delta : int) Fraction du signal à récupérer pour moyenner le points de superposition\n",
    "        __________\n",
    "        \n",
    "        return: (DataFrame) contenant les signaux superposés\n",
    "    '''\n",
    "    \n",
    "    signaux_superposé = signaux\n",
    "    \n",
    "    # Moyenne 1er dixième\n",
    "    fst_mean = signaux.iloc[:int(len(signaux)/delta),:].iloc[:,1].mean()\n",
    "    \n",
    "    # Distance entre les signaux et 0\n",
    "    d = 0 - fst_mean\n",
    "    \n",
    "    signaux_superposé.iloc[:,1:] = signaux.iloc[:,1:].apply(lambda x: x+d, axis=1)\n",
    "    \n",
    "    return signaux_superposé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance de class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_instance_class(dict_trucks_class, directory=\"backup/instance/\", filename=\"class_trucks.sig\"):\n",
    "    '''\n",
    "        Sauvegarde de toutes les instances 'Signal' créées lors de la récupération des fichiers signaux\n",
    "        __________\n",
    "        \n",
    "        param:\n",
    "            - (dict_trucks_class : dict) Dictionnaire des class contenant comme clé, le nom du fichier et comme valeur\n",
    "                l'instance de class\n",
    "            - (directory : str) Dossier de sauvegarde des instances de class\n",
    "            - (filename : str) Nom du fichier de sauvegarde des instances de class\n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    with open(directory+filename, 'wb') as file:\n",
    "        cloudpickle.dump(list_trucks_class, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_instance_class(directory=\"backup/instance/\", filename=\"class_trucks.sig\"):\n",
    "    '''\n",
    "        Récupération de toutes les instances 'Signal' sauvegardé dans 'directory' avec le nom 'filename'.\n",
    "        __________\n",
    "        \n",
    "        param:\n",
    "            - (directory : str) Dossier de sauvegarde des instances de class\n",
    "            - (filename : str) Nom du fichier de sauvegarde des instances de class\n",
    "        __________\n",
    "        \n",
    "        return: (Dictionnaire) contenant comme clé, le nom du fichier et comme valeur l'instance de class\n",
    "    '''\n",
    "    with open(directory+filename, 'rb') as file:\n",
    "        trucks = cloudpickle.load(file)\n",
    "        \n",
    "    return trucks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
